{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import random\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Pearson vs Spearman Correlation (4 points)\n",
    "\n",
    "## Objective\n",
    "Understand and compare how **Pearson** and **Spearman** correlations measure relationships between variables —  \n",
    "specifically **linear** versus **monotonic** associations — using real-world data from the **World Happiness Report (2024)**.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset: World Happiness Report (2024)\n",
    "\n",
    "This dataset, provided to you from Kaggle, summarizes survey data collected from over 130 countries worldwide.  \n",
    "Each record represents one country and its average well-being score based on multiple social and economic indicators.\n",
    "\n",
    "---\n",
    "\n",
    "### Goal of This Exercise\n",
    "You will:\n",
    "1. Compute and compare **Pearson** and **Spearman** correlations for all predictors with **Ladder score (Happiness)**.  \n",
    "2. Visualize the relationships between happiness and its key factors using **scatterplots with trendlines**.  \n",
    "3. Identify which features show **linear**, **nonlinear**, or **noisy** relationships — where Pearson and Spearman diverge.  \n",
    "4. Interpret the findings to understand when each method should be preferred.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "url = \"World-happiness-report-2024.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Basic info\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_columns = [\"Ladder score\", \"Log GDP per capita\", 'Social support', 'Healthy life expectancy', 'Freedom to make life choices', 'Generosity','Perceptions of corruption', 'Dystopia + residual' ]\n",
    "df = df[happiness_columns].dropna()\n",
    "scaler = StandardScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "sns.pairplot(df[happiness_columns])\n",
    "plt.suptitle(\"Pairwise Relationships among Key Happiness Indicators\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO (Exercise 1.1) (2 points)\n",
    "\n",
    "In this step, you will calculate how strongly each factor is related to **Happiness (Ladder score)** using two correlation methods:\n",
    "\n",
    "1. **Pearson correlation**.  \n",
    "\n",
    "2. **Spearman correlation**.  \n",
    "\n",
    "### Instructions\n",
    "- Use the `.corr()` function in pandas to compute both Pearson and Spearman correlation coefficients.  \n",
    "- Extract only the correlations with **'Ladder score'**.  \n",
    "- Sort the results from highest to lowest to see which factors have the strongest relationship with happiness.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# TODO Implement Pearson and Spearman Correlations\n",
    "# ------------------------------------------------\n",
    "\n",
    "pearson_corr = \n",
    "spearman_corr = \n",
    "\n",
    "# ----------------------------\n",
    "# Implementation Ends Here\n",
    "# ----------------------------\n",
    "\n",
    "compare = pd.DataFrame({'Pearson': pearson_corr, 'Spearman': spearman_corr})\n",
    "compare = compare.drop('Ladder score', errors='ignore')\n",
    "compare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 1.2 – Visualizing Correlations with Regression Plots** (2 points)\n",
    "\n",
    "In this exercise, you will **visualize and quantify the relationships** between key factors and the **Happiness (Ladder score)** using scatter plots and correlation metrics.\n",
    "\n",
    "Each subplot will show how a specific feature (e.g., GDP, life expectancy, social support) relates to happiness, helping you identify both **direction** (positive or negative) and **strength** of association.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "\n",
    "For each feature in `happiness_columns`, calculate two types of correlation with **`Ladder score`**:\n",
    "\n",
    "   - **Pearson correlation** \n",
    "   - **Spearman correlation** \n",
    "\n",
    "*Hint:* Both correlations can be computed using functions from `scipy.stats`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(happiness_columns):\n",
    "    sns.regplot(\n",
    "        data=df,\n",
    "        x=col,\n",
    "        y='Ladder score',\n",
    "        ax=axes[i],\n",
    "        scatter_kws={'alpha': 0.6},\n",
    "        line_kws={'color': 'red'}\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # TODO Implement Pearson and Spearman Correlations\n",
    "    # ------------------------------------------------\n",
    "    pearson_val, _ = \n",
    "    spearman_val, _ = \n",
    "\n",
    "    # ----------------------------\n",
    "    # Implementation Ends Here\n",
    "    # ----------------------------\n",
    "    \n",
    "    axes[i].set_title(\n",
    "        f\"{col}\\nPearson = {pearson_val:.2f}, Spearman = {spearman_val:.2f}\",\n",
    "        fontsize=10\n",
    "    )\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel(\"Ladder score\")\n",
    "\n",
    "# Adjust layout and title\n",
    "plt.suptitle(\"Happiness (Ladder Score) vs Key Predictors\", fontsize=14, y=1.02)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Simpson’s Paradox (6 points)\n",
    "\n",
    "## Objective\n",
    "Understand **Simpson’s Paradox** — a situation where a trend appears in aggregated data but reverses or disappears when the data are divided into groups.\n",
    "\n",
    "You’ll explore this paradox using the **World Happiness Report (2024)** dataset, by analyzing the relationship between **GDP per capita** and **Happiness**, both overall and within different **world regions**.\n",
    "\n",
    "---\n",
    "\n",
    "**Example idea:**  \n",
    "\n",
    "Globally, countries with higher GDP have higher happiness.  But within each region, that relationship might weaken or even reverse.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"World-happiness-report-2024.csv\")\n",
    "df = df.dropna()\n",
    "# df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 2.1 – Global Relationship: GDP vs Happiness** (3 points)\n",
    "\n",
    "In this exercise, you will focus on a single predictor — **Log GDP per capita** — to explore its global relationship with **Happiness (Ladder score)**.  \n",
    "You will calculate the correlation between these two variables and visualize their linear trend.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "\n",
    "**Compute both correlation coefficients** between `Log GDP per capita` and `Ladder score`:\n",
    "\n",
    "   - **Pearson correlation** \n",
    "   - **Spearman correlation**\n",
    "\n",
    "*Hint:* You can find both correlation functions in `scipy.stats`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# TODO Implement Pearson Spearman Correlations for predictor Log GDP per capita\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "pearson_global, _ = \n",
    "spearman_global, _ = \n",
    "print(f\"Global Pearson correlation (GDP vs Happiness): {pearson_global:.2f}\")\n",
    "print(f\"Global Spearman correlation (GDP vs Happiness): {spearman_global:.2f}\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Implementation Ends Here\n",
    "# ----------------------------\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.regplot(data=df, x='Log GDP per capita', y='Ladder score', color='red', scatter_kws={'alpha':0.6})\n",
    "plt.title(\"Global Relationship: GDP vs Happiness\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 2.2 – Regional Correlations: GDP vs Happiness** (3 points)\n",
    "\n",
    "In this exercise, you will analyze how the relationship between **Log GDP per capita** and **Happiness (Ladder score)** varies **across regions**.  \n",
    "This helps you understand whether the global GDP–Happiness trend is consistent or differs regionally.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "\n",
    "1. **Group the data by region** using the column `Regional indicator`.\n",
    "\n",
    "2. **Within each region**, compute the **Pearson correlation** between:\n",
    "   - `Log GDP per capita`\n",
    "   - `Ladder score`\n",
    "\n",
    "\n",
    "Hint - Use: pearsonr from scipy.stats\n",
    "\n",
    "*Another Hint:* You can follow these steps to compute the correlation by region:\n",
    "\n",
    "1. **Group the data** by `Regional indicator` using the `groupby()` method.  \n",
    "2. **Within each group**, calculate the correlation between `Log GDP per capita` and `Ladder score` using a correlation function such as `pearsonr` from `scipy.stats`.  \n",
    "3. **Extract the correlation value** (the first element returned by `pearsonr`).  \n",
    "4. **Sort the results** to identify which regions show the strongest positive or negative relationships.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# TODO Implement Pearson Spearman Correlations for predictor Log GDP per capita by region\n",
    "# ----------------------------------------------------------------------------------------\n",
    "regional_corr = \n",
    "\n",
    "# ----------------------------\n",
    "# Implementation Ends Here\n",
    "# ----------------------------\n",
    "\n",
    "print(\"Regional Pearson correlations (GDP vs Happiness):\")\n",
    "display(regional_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of unique regions\n",
    "regions = df['Regional indicator'].unique()\n",
    "num_regions = len(regions)\n",
    "\n",
    "# Determine grid size automatically\n",
    "ncols = 3\n",
    "nrows = (num_regions + ncols - 1) // ncols\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, region in enumerate(regions):\n",
    "    sub = df[df['Regional indicator'] == region]\n",
    "\n",
    "    # Compute regional Pearson correlation\n",
    "    pearson_val, _ = pearsonr(sub['Log GDP per capita'], sub['Ladder score'])\n",
    "\n",
    "    sns.regplot(\n",
    "        data=sub,\n",
    "        x='Log GDP per capita',\n",
    "        y='Ladder score',\n",
    "        ax=axes[i],\n",
    "        scatter_kws={'alpha':0.6, 's':50},\n",
    "        line_kws={'color':'red'}\n",
    "    )\n",
    "    \n",
    "    axes[i].set_title(f\"{region}\\nPearson r = {pearson_val:.2f}\", fontsize=10)\n",
    "    axes[i].set_xlabel(\"Log GDP per capita\")\n",
    "    axes[i].set_ylabel(\"Ladder score\")\n",
    "\n",
    "# Remove unused subplots if regions < grid size\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.suptitle(\"Simpson’s Paradox: GDP vs Happiness by Region\", fontsize=14, y=0.98)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Digital Wellbeing and Happiness Prediction Using Decision Trees (14 points)\n",
    "\n",
    "### Objective: Learn how to apply **Decision Trees** for **classification tasks** using a real-world dataset on digital wellbeing. You will explore how behavioral factors like screen time, sleep quality, stress, and exercise relate to happiness and train decision tree models using different splitting criteria.\n",
    "\n",
    "> **How can we tell which features matter and whether the model is good — without consulting an oracle?**\n",
    "\n",
    "---\n",
    "\n",
    "### **Focus Areas**\n",
    "\n",
    "1. **Feature Importance**\n",
    "   - Examine which variables the Decision Tree considers most influential.\n",
    "\n",
    "2. **Model Evaluation Without an Oracle**\n",
    "   - Evaluate metrics such as **accuracy**, **precision**, **recall**, and **F1-score**.\n",
    "   - Review the **confusion matrix** to understand where the model succeeds or fails.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Load Dataset\n",
    "\n",
    "df = pd.read_csv(\"Mental_Health_and_Social_Media_Balance_Dataset.csv\")\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n",
    "\n",
    "# Drop ID column (non-informative)\n",
    "df = df.drop(columns=[\"User_ID\"])\n",
    "\n",
    "#Create Target Variable\n",
    "# Happy (>=8) → 1, Unhappy (<8) → 0\n",
    "df[\"Happiness_Status\"] = np.where(df[\"Happiness_Index(1-10)\"] >= 8, 1, 0)\n",
    "\n",
    "# Drop the original happiness index to avoid leakage\n",
    "df = df.drop(columns=[\"Happiness_Index(1-10)\"])\n",
    "\n",
    "# Encode Categorical Variables\n",
    "\n",
    "categorical_cols = [\"Gender\", \"Social_Media_Platform\"]\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "\n",
    "df_encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 3.1 – Feature Correlation with Happiness Status** (2 points)\n",
    "\n",
    "In this exercise, you will compute how strongly each encoded feature is related to **Happiness_Status** (binary classification: Happy vs Unhappy).  \n",
    "You will use two correlation methods to capture both linear and rank-based relationships between predictors and happiness.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "\n",
    "1. **Work with the encoded dataset** `df_encoded`, which includes numerical and categorical variables converted into numeric form.\n",
    "\n",
    "2. **Compute correlation coefficients** between each feature and the target variable `Happiness_Status` using:\n",
    "   - **Pearson correlation** on Happiness_Status\n",
    "   - **Spearman correlation** on Happiness_Status\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# TODO Implement Pearson and Spearman Correlations\n",
    "# ------------------------------------------------\n",
    "\n",
    "pearson_corr = \n",
    "spearman_corr = \n",
    "\n",
    "# ----------------------------\n",
    "# Implementation Ends Here\n",
    "# ----------------------------\n",
    "\n",
    "compare = pd.DataFrame({'Pearson': pearson_corr, 'Spearman': spearman_corr})\n",
    "compare = compare.drop('Ladder score', errors='ignore')\n",
    "compare\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 3.2 – Splitting the Dataset into Training and Testing Sets** (2 points)\n",
    "\n",
    "In this exercise, you will split your encoded dataset into **training** and **testing** subsets to prepare for model building.  \n",
    "This ensures that you can train your model on one portion of the data and evaluate its performance on unseen data, avoiding overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "Use sklearn train_test_split\n",
    "   ```python\n",
    "   from sklearn.model_selection import train_test_split \n",
    "\n",
    "   params := (X, y, test_size=0.3, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df_encoded.drop(\"Happiness_Status\", axis=1)\n",
    "y = df_encoded[\"Happiness_Status\"]\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# TODO Slipt your dataset into Train and Test using sklearn train_test_split\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = \n",
    "\n",
    "# ----------------------------\n",
    "# Implementation Ends Here\n",
    "# ----------------------------\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \" Test size:\", X_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 3.3 – Building Decision Trees with Different Splitting Criteria** (4 points)\n",
    "\n",
    "In this exercise, you will train and evaluate **Decision Tree classifiers** using three different impurity measures:\n",
    "- **Gini Index**\n",
    "- **Entropy**\n",
    "- **Log Loss**\n",
    "\n",
    "The goal is to compare how each criterion affects the model’s performance and decision boundaries.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "\n",
    "1. For each criterion (`\"gini\"`, `\"entropy\"`, and `\"log_loss\"`), build and train a Decision Tree model using the training data.  \n",
    "2. Evaluate each model on the test set and record the **accuracy score**.  \n",
    "3. Use random_state = 42. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "criteria = [\"gini\", \"entropy\", \"log_loss\"] \n",
    "results = {}\n",
    "\n",
    "for c in criteria:\n",
    "    # --------------------------------------------------------------------------\n",
    "    # TODO Implement Decision Trees for all the three criterion mentioned above\n",
    "    # --------------------------------------------------------------------------\n",
    "    clf = \n",
    "    clf.\n",
    "    y_pred = \n",
    "    acc = \n",
    "    # ----------------------------\n",
    "    # Implementation Ends Here\n",
    "    # ----------------------------\n",
    "    results[c] = {\"model\": clf, \"accuracy\": acc}\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Criterion: {c.upper()}\")\n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"Unhappy\", \"Happy\"]))\n",
    "    \n",
    "    # Confusion matrix visualization\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        clf,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=[\"Unhappy\", \"Happy\"],\n",
    "        cmap=\"Blues\",\n",
    "        values_format=\".0f\"\n",
    "    )\n",
    "    plt.title(f\"Confusion Matrix ({c.upper()} Criterion)\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.grid(False)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 3.4 – Exploring Decision Tree Hyperparameters** (4 points)\n",
    "\n",
    "In this exercise, you will explore how **Decision Tree performance** changes with different model configurations.  \n",
    "You’ll systematically vary three parameters — **splitting criterion**, **maximum depth**, and **minimum samples required to split** — to observe their effect on accuracy and F1-score.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "\n",
    "1. **Loop over multiple configurations:**\n",
    "   - Use the following lists for testing:\n",
    "     - `criteria = ['gini', 'entropy', 'log_loss']`\n",
    "     - `depth_values = [4, 6, 8, 10]`\n",
    "     - `min_samples_split = [2, 5, 10, 20]`\n",
    "\n",
    "2. For each combination:\n",
    "   - Build and train a **DecisionTreeClassifier** using the specified parameters.  \n",
    "   - Use random_state = 42 for the classifier\n",
    "   - Evaluate its performance on the test data.\n",
    "\n",
    "3. **Compute and record metrics:**\n",
    "   - **Accuracy** – overall prediction correctness.  \n",
    "   - **F1 Score** – balance between precision and recall.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    ConfusionMatrixDisplay, classification_report\n",
    ")\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "depth_values = [4, 6, 8, 10]\n",
    "min_samples_values = [2, 5, 10, 20]\n",
    "criteria = ['gini', 'entropy', 'log_loss']\n",
    "\n",
    "records = []\n",
    "\n",
    "for crit in criteria:\n",
    "    for max_depth in depth_values:\n",
    "        for min_split in min_samples_values:\n",
    "            # --------------------------------------------------------------------------------------------\n",
    "            # TODO Implement Decision Trees for all the three criteria, depth_values and min_sample_values\n",
    "            # --------------------------------------------------------------------------------------------\n",
    "            clf = \n",
    "            clf.\n",
    "            y_pred = \n",
    "\n",
    "            # --------------------------------------------------------------------------------------------\n",
    "            # TODO Compute Accuracy and F1 scores\n",
    "            # --------------------------------------------------------------------------------------------\n",
    "            acc = \n",
    "            f1 = \n",
    "\n",
    "            # ----------------------------\n",
    "            # Implementation Ends Here\n",
    "            # ----------------------------\n",
    "            records.append({\n",
    "                \"Criterion\": crit,\n",
    "                \"Max Depth\": max_depth,\n",
    "                \"Min Samples Split\": min_split,\n",
    "                \"Accuracy\": acc,\n",
    "                \"F1 Score\": f1,\n",
    "                \"Model\": clf\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(records)\n",
    "\n",
    "# Display neatly sorted table\n",
    "display(\n",
    "    results_df.sort_values(by=\"Accuracy\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    "    .style.background_gradient(subset=[\"Accuracy\", \"F1 Score\"], cmap=\"YlGn\")\n",
    "    .format({\"Accuracy\": \"{:.3f}\", \"F1 Score\": \"{:.3f}\"})\n",
    "    .set_caption(\"Decision Tree Performance Across Hyperparameters\")\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 3.5 – Evaluating and Interpreting the Best Decision Tree Model** (2 points)\n",
    "\n",
    "In this exercise, you will identify the **best-performing Decision Tree model** from all tested hyperparameter combinations and evaluate it using multiple performance metrics and visualizations.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "**Compute model performance metrics:**\n",
    "   - Calculate and print using sklean packages on y_test, y_pred_best:\n",
    "     - **Accuracy**\n",
    "     - **Precision**\n",
    "     - **Recall**\n",
    "     - **F1 Score**\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = results_df.loc[results_df[\"Accuracy\"].idxmax()]\n",
    "best_model = best_row[\"Model\"]\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"BEST MODEL FOUND\")\n",
    "print('='*70)\n",
    "print(f\"Criterion          : {best_row['Criterion'].upper()}\")\n",
    "print(f\"Max Depth          : {best_row['Max Depth']}\")\n",
    "print(f\"Min Samples Split  : {best_row['Min Samples Split']}\")\n",
    "print(f\"Accuracy           : {best_row['Accuracy']:.3f}\")\n",
    "print(f\"F1 Score           : {best_row['F1 Score']:.3f}\")\n",
    "print('='*70)\n",
    "\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "# TODO Compute Accuracy, F1, recall and precision scores on y_test and y_pred_best\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "acc = \n",
    "prec = \n",
    "rec = \n",
    "f1 = \n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Implementation Ends Here\n",
    "# ----------------------------\n",
    "\n",
    "print(\"\\nClassification Metrics Summary\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Accuracy       : {acc:.3f}\")\n",
    "print(f\"Precision      : {prec:.3f}\")\n",
    "print(f\"Recall         : {rec:.3f}\")\n",
    "print(f\"F1 Score       : {f1:.3f}\")\n",
    "print(\"-\" * 70)\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_best, target_names=[\"Unhappy\", \"Happy\"]))\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_estimator(\n",
    "    best_model,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    display_labels=[\"Unhappy\", \"Happy\"],\n",
    "    cmap=\"Purples\",\n",
    "    values_format=\".0f\"\n",
    ")\n",
    "plt.title(\n",
    "    f\"Confusion Matrix - Best Model ({best_row['Criterion'].upper()} | Depth={best_row['Max Depth']} | MinSplit={best_row['Min Samples Split']})\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\"\n",
    ")\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "importances = pd.Series(best_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importances.values, y=importances.index, palette=\"mako\")\n",
    "plt.title(\n",
    "    f\"Feature Importance - Best Model ({best_row['Criterion'].upper()})\",\n",
    "    fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ## Save the Decision Tree of the Best Model as PNG\n",
    "\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Identify the best-performing model\n",
    "best_criterion = max(results, key=lambda c: results[c][\"accuracy\"])\n",
    "best_model = results[best_criterion][\"model\"]\n",
    "\n",
    "print(f\"\\nBest performing model: {best_criterion.upper()} (Accuracy = {results[best_criterion]['accuracy']:.3f})\")\n",
    "\n",
    "# Create a large, high-resolution figure\n",
    "fig = plt.figure(figsize=(60, 20))  # adjust for longer arrows and more spacing\n",
    "tree.plot_tree(\n",
    "    best_model,\n",
    "    feature_names=X.columns,\n",
    "    class_names=[\"Unhappy\", \"Happy\"],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=8,\n",
    "    proportion=True\n",
    ")\n",
    "\n",
    "# Save as high-resolution PNG\n",
    "output_path = f\"decision_tree_best_{best_criterion}.png\"\n",
    "fig.savefig(output_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "plt.close(fig)\n",
    "print(f\"Saved best model tree as: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercise 4: Questions and Answers** (10 points)\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Correlation vs. Causation**  \n",
    "In the World Happiness dataset, both Pearson and Spearman correlations show strong relationships between GDP and Happiness.  \n",
    "- Why does a high correlation *not necessarily* imply that higher GDP causes higher happiness?  \n",
    "- What factors could confound this relationship?\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Simpson’s Paradox**  \n",
    "When you analyzed GDP vs. Happiness by region, how did the direction or strength of correlation change compared to the global trend?  \n",
    "- What does this reveal about the importance of analyzing data within subgroups?\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Which model is the best, based on splitting criterion**  \n",
    "- Which **splitting criterion** (Gini, Entropy, or Log Loss) produced the **best accuracy** in your experiment? Specify the **hyperparameters** (`max_depth` and `min_samples_split`) that gave the highest accuracy.  \n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Which model is the best?**  \n",
    "- According to the **feature importance plot**, which variable had the **greatest influence** on predicting happiness?  \n",
    "- Does this result match your **intuition** about which behaviors (e.g., screen time, sleep, stress, exercise) most affect happiness?  \n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Tree Interpretability**  \n",
    "- Why are **Decision Trees** considered **interpretable models**?  \n",
    "- What are some **limitations** of that interpretability when trees become deeper or more complex?\n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmexp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
